import numpy as np
import matplotlib.pyplot as plt

# Function to minimize (example: f(x) = x^2)
def function(x):
    return x**2

# Gradient of the function (example: f'(x) = 2*x)
def gradient(x):
    return 2*x

# Gradient descent optimization
def gradient_descent(learning_rate, max_iterations):
    x = 10  # Initial guess
    history = [x]  # List to store the history of x values

    for i in range(max_iterations):
        x = x - learning_rate * gradient(x)  # Update x using gradient descent
        history.append(x)

    return history

# Set hyperparameters
learning_rate = 0.1
max_iterations = 50

# Run gradient descent
history = gradient_descent(learning_rate, max_iterations)

# Plot the function and the optimization path
x_values = np.linspace(-12, 12, 100)
plt.plot(x_values, function(x_values), label='f(x) = x^2')
plt.scatter(history, function(np.array(history)), color='red', label='Gradient Descent Path')
plt.title('Gradient Descent Optimization')
plt.xlabel('x')
plt.ylabel('f(x)')
plt.legend()
plt.grid(True)
plt.show()
